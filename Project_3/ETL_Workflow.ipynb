{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract: Players_Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PlayerID FirstName    LastName           Status  TeamID Team Position  \\\n",
      "0  30000007     Carey       Price  Injured Reserve       4  MON        G   \n",
      "1  30000012      Lars       Eller           Active      14  PIT        C   \n",
      "2  30000015   Brendan   Gallagher           Active       4  MON       RW   \n",
      "3  30000019       Max  Pacioretty           Active      15  WAS       LW   \n",
      "4  30000031     Peter     Holland           Minors      19  COL        C   \n",
      "\n",
      "   Jersey Catches Shoots  ...  DepthChartPosition  DepthChartOrder  \\\n",
      "0    31.0       L   None  ...                None              NaN   \n",
      "1    20.0    None      L  ...                   C              1.0   \n",
      "2    11.0    None      R  ...                  LW              1.0   \n",
      "3    67.0    None      L  ...                  LW              1.0   \n",
      "4     NaN    None      L  ...                None              NaN   \n",
      "\n",
      "  GlobalTeamID   FantasyDraftName FantasyDraftPlayerID UsaTodayPlayerID  \\\n",
      "0     30000004               None                  NaN        8256983.0   \n",
      "1     30000014         Lars Eller             392954.0        8314832.0   \n",
      "2     30000004  Brendan Gallagher             555807.0        8256974.0   \n",
      "3     30000015     Max Pacioretty             392964.0        8314929.0   \n",
      "4     30000019      Peter Holland            1416068.0            135.0   \n",
      "\n",
      "                                 UsaTodayHeadshotUrl  \\\n",
      "0  http://cdn.usatsimg.com/api/download/?imageID=...   \n",
      "1  http://cdn.usatsimg.com/api/download/?imageID=...   \n",
      "2  http://cdn.usatsimg.com/api/download/?imageID=...   \n",
      "3  http://cdn.usatsimg.com/api/download/?imageID=...   \n",
      "4  http://cdn.usatsimg.com/api/download/?imageID=...   \n",
      "\n",
      "                     UsaTodayHeadshotNoBackgroundUrl  UsaTodayHeadshotUpdated  \\\n",
      "0  http://cdn.usatsimg.com/api/download/?imageID=...      2023-10-02T13:18:01   \n",
      "1  http://cdn.usatsimg.com/api/download/?imageID=...      2021-09-30T15:30:07   \n",
      "2  http://cdn.usatsimg.com/api/download/?imageID=...      2023-10-02T12:32:05   \n",
      "3  http://cdn.usatsimg.com/api/download/?imageID=...      2023-10-06T11:22:34   \n",
      "4  http://cdn.usatsimg.com/api/download/?imageID=...                     None   \n",
      "\n",
      "   UsaTodayHeadshotNoBackgroundUpdated  \n",
      "0                  2023-10-02T13:17:57  \n",
      "1                  2023-05-31T14:18:55  \n",
      "2                  2023-10-02T12:32:01  \n",
      "3                  2023-10-06T11:22:11  \n",
      "4                                 None  \n",
      "\n",
      "[5 rows x 43 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from config import api_key\n",
    "\n",
    "def fetch_and_inspect_api_data():\n",
    "    url = f'https://api.sportsdata.io/v3/nhl/scores/json/Players?key={api_key}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert the response to JSON\n",
    "        \n",
    "        # Convert the data to a pandas DataFrame for inspection\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Inspect the first few rows of the DataFrame\n",
    "        print(df.head())\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the API\")\n",
    "        return None\n",
    "\n",
    "# Now, call the function to fetch the data and inspect it\n",
    "players_active_df = fetch_and_inspect_api_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform: Players_active\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PlayerID FirstName    LastName           Status  TeamID Team Position  \\\n",
      "0  30000007     Carey       Price  Injured Reserve       4  MON        G   \n",
      "1  30000012      Lars       Eller           Active      14  PIT        C   \n",
      "2  30000015   Brendan   Gallagher           Active       4  MON       RW   \n",
      "3  30000019       Max  Pacioretty           Active      15  WAS       LW   \n",
      "4  30000031     Peter     Holland           Minors      19  COL        C   \n",
      "\n",
      "   Height  Weight   BirthDate      BirthPlace  \n",
      "0      75     217  08/16/1987  Anahim Lake,BC  \n",
      "1      74     205  05/08/1989         Rodovre  \n",
      "2      69     183  05/06/1992     Edmonton,AB  \n",
      "3      74     217  11/20/1988   New Canaan,CT  \n",
      "4      74     193  01/14/1991      Toronto,ON  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1855 entries, 0 to 1854\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PlayerID    1855 non-null   int64 \n",
      " 1   FirstName   1855 non-null   object\n",
      " 2   LastName    1855 non-null   object\n",
      " 3   Status      1855 non-null   object\n",
      " 4   TeamID      1855 non-null   int64 \n",
      " 5   Team        1855 non-null   object\n",
      " 6   Position    1855 non-null   object\n",
      " 7   Height      1855 non-null   int64 \n",
      " 8   Weight      1855 non-null   int64 \n",
      " 9   BirthDate   1854 non-null   object\n",
      " 10  BirthPlace  1855 non-null   object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 159.5+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenar\\AppData\\Local\\Temp\\ipykernel_9712\\2405883503.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop_duplicates(subset='PlayerID', inplace=True)\n",
      "C:\\Users\\lenar\\AppData\\Local\\Temp\\ipykernel_9712\\2405883503.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BirthPlace'] = df.apply(lambda row: ','.join(filter(None, [row['BirthCity'], row['BirthState']])), axis=1)\n",
      "C:\\Users\\lenar\\AppData\\Local\\Temp\\ipykernel_9712\\2405883503.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['BirthDate'] = pd.to_datetime(df['BirthDate']).dt.strftime('%m/%d/%Y')\n",
      "C:\\Users\\lenar\\AppData\\Local\\Temp\\ipykernel_9712\\2405883503.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(['BirthCity', 'BirthState'], axis=1, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def transform_players_active_df_v2(df):\n",
    "    # Step 1: Select only the relevant columns. Adjust this list as per your requirement.\n",
    "    relevant_columns = ['PlayerID', 'FirstName', 'LastName', 'Status', 'TeamID', 'Team', 'Position', 'Height', 'Weight', 'BirthDate', 'BirthCity', 'BirthState']\n",
    "    df = df[relevant_columns]\n",
    "\n",
    "    # Step 2: Drop duplicates based on 'PlayerID'\n",
    "    df.drop_duplicates(subset='PlayerID', inplace=True)\n",
    "\n",
    "    # Step 3: Combine 'BirthCity' and 'BirthState' into 'BirthPlace'\n",
    "    # Use a lambda function to handle rows where either city or state might be missing\n",
    "    df['BirthPlace'] = df.apply(lambda row: ','.join(filter(None, [row['BirthCity'], row['BirthState']])), axis=1)\n",
    "    \n",
    "    # Format BirthDate to mm/dd/yyyy\n",
    "    df['BirthDate'] = pd.to_datetime(df['BirthDate']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "    # Drop the original 'BirthCity' and 'BirthState' columns as they're no longer needed\n",
    "    df.drop(['BirthCity', 'BirthState'], axis=1, inplace=True)\n",
    "\n",
    "    # Inspect the transformed DataFrame \n",
    "    print(df.head())\n",
    "    print(df.info())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the transformation function\n",
    "players_active_df_transformed = transform_players_active_df_v2(players_active_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1855 entries, 0 to 1854\n",
      "Data columns (total 11 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   PlayerID    1855 non-null   int64 \n",
      " 1   FirstName   1855 non-null   object\n",
      " 2   LastName    1855 non-null   object\n",
      " 3   Status      1855 non-null   object\n",
      " 4   TeamID      1855 non-null   int64 \n",
      " 5   Team        1855 non-null   object\n",
      " 6   Position    1855 non-null   object\n",
      " 7   Height      1855 non-null   int64 \n",
      " 8   Weight      1855 non-null   int64 \n",
      " 9   BirthDate   1854 non-null   object\n",
      " 10  BirthPlace  1855 non-null   object\n",
      "dtypes: int64(4), object(7)\n",
      "memory usage: 159.5+ KB\n"
     ]
    }
   ],
   "source": [
    "# Check data types\n",
    "\n",
    "players_active_df_transformed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database.\n"
     ]
    }
   ],
   "source": [
    "# Establish database connection\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "def create_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname='NHL',\n",
    "            user='postgres',\n",
    "            password='postgres',\n",
    "            host='localhost'\n",
    "\n",
    "        )\n",
    "        print(\"Successfully connected to the database.\")\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f'Error: Could not make connection to PostGreSQL database')\n",
    "        print(e)\n",
    "\n",
    "conn = create_connection()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load: Players_Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into the database.\n"
     ]
    }
   ],
   "source": [
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "def load_data_to_db(conn, df, table_name):\n",
    "    \"\"\"\n",
    "    Load data from a DataFrame to a specified table in the PostgreSQL database.\n",
    "    \n",
    "    :param conn: Connection object to the database\n",
    "    :param df: DataFrame containing the data to load\n",
    "    :param table_name: Name of the table where data will be inserted\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Define INSERT INTO statement\n",
    "    columns = df.columns.tolist()  # Get the column names from the DataFrame\n",
    "    columns_str = ', '.join(columns)  # Create a string of column names for the SQL statement\n",
    "    values_str = ', '.join(['%s' for _ in columns])  # Create a string of '%s' placeholders for the values\n",
    "    insert_query = f\"INSERT INTO {table_name} ({columns_str}) VALUES ({values_str}) ON CONFLICT DO NOTHING;\"\n",
    "    \n",
    "    # Prepare the data for insertion\n",
    "    data_to_insert = [tuple(row) for row in df.to_numpy()]\n",
    "    \n",
    "    try:\n",
    "        # Use execute_batch for efficient bulk inserts\n",
    "        execute_batch(cursor, insert_query, data_to_insert)\n",
    "        conn.commit()\n",
    "        print(\"Data loaded successfully into the database.\")\n",
    "    except psycopg2.Error as e:\n",
    "        conn.rollback()  # Rollback the transaction in case of error\n",
    "        print(\"An error occurred while inserting data into the database:\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "table_name = 'players'  \n",
    "load_data_to_db(conn, players_active_df_transformed, table_name)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract: Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TeamID  Key  Active      City       Name  StadiumID Conference  Division  \\\n",
      "0       1  BOS    True    Boston     Bruins        3.0    Eastern  Atlantic   \n",
      "1       2  BUF    True   Buffalo     Sabres        4.0    Eastern  Atlantic   \n",
      "2       3  DET    True   Detroit  Red Wings       11.0    Eastern  Atlantic   \n",
      "3       4  MON    True  Montreal  Canadiens       16.0    Eastern  Atlantic   \n",
      "4       5  OTT    True    Ottawa   Senators       21.0    Eastern  Atlantic   \n",
      "\n",
      "  PrimaryColor SecondaryColor TertiaryColor QuaternaryColor  \\\n",
      "0       000000         FDB717          None            None   \n",
      "1       003087         FFB81C        FFFFFF            None   \n",
      "2       C8102E         FFFFFF          None            None   \n",
      "3       A6192E         FFFFFF        001E62            None   \n",
      "4       010101         C8102E        B9975B          FFFFFF   \n",
      "\n",
      "                                    WikipediaLogoUrl WikipediaWordMarkUrl  \\\n",
      "0  https://upload.wikimedia.org/wikipedia/commons...                 None   \n",
      "1  https://upload.wikimedia.org/wikipedia/en/9/9e...                 None   \n",
      "2  https://upload.wikimedia.org/wikipedia/en/e/e0...                 None   \n",
      "3  https://upload.wikimedia.org/wikipedia/commons...                 None   \n",
      "4  https://upload.wikimedia.org/wikipedia/en/d/db...                 None   \n",
      "\n",
      "   GlobalTeamID                 HeadCoach  \n",
      "0      30000001            Jim Montgomery  \n",
      "1      30000002               Don Granato  \n",
      "2      30000003             Derek Lalonde  \n",
      "3      30000004          Martin St. Louis  \n",
      "4      30000005  Jacques Martin (Interim)  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from config import api_key\n",
    "\n",
    "def fetch_and_inspect_api_data():\n",
    "    url = f'https://api.sportsdata.io/v3/nhl/scores/json/AllTeams?key={api_key}'\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()  # Convert the response to JSON\n",
    "        \n",
    "        # Convert the data to a pandas DataFrame for inspection\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Inspect the first few rows of the DataFrame\n",
    "        print(df.head())\n",
    "        \n",
    "        return df\n",
    "    else:\n",
    "        print(\"Failed to retrieve data from the API\")\n",
    "        return None\n",
    "\n",
    "# Now, call the function to fetch the data and inspect it\n",
    "teams_active_df = fetch_and_inspect_api_data()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform: Teams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 16 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   TeamID                40 non-null     int64  \n",
      " 1   Key                   40 non-null     object \n",
      " 2   Active                40 non-null     bool   \n",
      " 3   City                  40 non-null     object \n",
      " 4   Name                  40 non-null     object \n",
      " 5   StadiumID             32 non-null     float64\n",
      " 6   Conference            32 non-null     object \n",
      " 7   Division              32 non-null     object \n",
      " 8   PrimaryColor          32 non-null     object \n",
      " 9   SecondaryColor        32 non-null     object \n",
      " 10  TertiaryColor         29 non-null     object \n",
      " 11  QuaternaryColor       13 non-null     object \n",
      " 12  WikipediaLogoUrl      32 non-null     object \n",
      " 13  WikipediaWordMarkUrl  0 non-null      object \n",
      " 14  GlobalTeamID          40 non-null     int64  \n",
      " 15  HeadCoach             32 non-null     object \n",
      "dtypes: bool(1), float64(1), int64(2), object(12)\n",
      "memory usage: 4.9+ KB\n"
     ]
    }
   ],
   "source": [
    "teams_active_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 40 entries, 0 to 39\n",
      "Data columns (total 11 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   TeamID        40 non-null     int64  \n",
      " 1   Name_         40 non-null     object \n",
      " 2   Abbreviation  40 non-null     object \n",
      " 3   City          40 non-null     object \n",
      " 4   StadiumID     32 non-null     float64\n",
      " 5   Conference    32 non-null     object \n",
      " 6   Division      32 non-null     object \n",
      " 7   HeadCoach     32 non-null     object \n",
      " 8   ColorCode     40 non-null     object \n",
      " 9   GlobalTeamID  40 non-null     int64  \n",
      " 10  Active        40 non-null     bool   \n",
      "dtypes: bool(1), float64(1), int64(2), object(7)\n",
      "memory usage: 3.3+ KB\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenar\\AppData\\Local\\Temp\\ipykernel_9712\\3641362884.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Key': 'Abbreviation'}, inplace=True)\n",
      "C:\\Users\\lenar\\AppData\\Local\\Temp\\ipykernel_9712\\3641362884.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Colors': 'ColorCode'}, inplace=True)\n",
      "C:\\Users\\lenar\\AppData\\Local\\Temp\\ipykernel_9712\\3641362884.py:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.rename(columns={'Name': 'Name_'}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def transform_teams_active_df_v2(df):\n",
    "    \n",
    "    # Make a 'Colors' column\n",
    "    df['Colors'] = df.apply(lambda row: ','.join(filter(None, [row['PrimaryColor'], row['SecondaryColor'], row['TertiaryColor'], row['QuaternaryColor']])), axis=1)\n",
    "    df.drop(['PrimaryColor', 'SecondaryColor', 'TertiaryColor', 'QuaternaryColor'], axis=1, inplace=True)\n",
    "\n",
    "    # Drop duplicates \n",
    "    df.drop_duplicates(subset='TeamID', inplace=True)\n",
    "\n",
    "    # Reorder columns\n",
    "    df = df[['TeamID', 'Name', 'Key', 'City', 'StadiumID', 'Conference', 'Division', 'HeadCoach', 'Colors',  'GlobalTeamID', 'Active']]\n",
    "\n",
    "    # Rename column\n",
    "    df.rename(columns={'Key': 'Abbreviation'}, inplace=True)\n",
    "    df.rename(columns={'Colors': 'ColorCode'}, inplace=True)\n",
    "    df.rename(columns={'Name': 'Name_'}, inplace=True)\n",
    "\n",
    "    \n",
    "    # Format BirthDate to mm/dd/yyyy\n",
    "    #df['BirthDate'] = pd.to_datetime(df['BirthDate']).dt.strftime('%m/%d/%Y')\n",
    "\n",
    "    \n",
    "    # Inspect the transformed DataFrame \n",
    "    #print(df.head())\n",
    "    print(df.info())\n",
    "\n",
    "    return df\n",
    "\n",
    "# Apply the transformation function\n",
    "teams_active_df_transformed = transform_teams_active_df_v2(teams_active_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to the database.\n"
     ]
    }
   ],
   "source": [
    "# Establish database connection\n",
    "\n",
    "import psycopg2\n",
    "\n",
    "def create_connection():\n",
    "    try:\n",
    "        conn = psycopg2.connect(\n",
    "            dbname='NHL',\n",
    "            user='postgres',\n",
    "            password='postgres',\n",
    "            host='localhost'\n",
    "\n",
    "        )\n",
    "        print(\"Successfully connected to the database.\")\n",
    "        return conn\n",
    "    except psycopg2.Error as e:\n",
    "        print(f'Error: Could not make connection to PostGreSQL database')\n",
    "        print(e)\n",
    "\n",
    "conn = create_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully into the database.\n"
     ]
    }
   ],
   "source": [
    "from psycopg2.extras import execute_batch\n",
    "\n",
    "def load_data_to_db(conn, df, table_name):\n",
    "    \"\"\"\n",
    "    Load data from a DataFrame to a specified table in the PostgreSQL database.\n",
    "    \n",
    "    :param conn: Connection object to the database\n",
    "    :param df: DataFrame containing the data to load\n",
    "    :param table_name: Name of the table where data will be inserted\n",
    "    \"\"\"\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # Define INSERT INTO statement\n",
    "    columns = df.columns.tolist()  # Get the column names from the DataFrame\n",
    "    columns_str = ', '.join(columns)  # Create a string of column names for the SQL statement\n",
    "    values_str = ', '.join(['%s' for _ in columns])  # Create a string of '%s' placeholders for the values\n",
    "    insert_query = f\"INSERT INTO {table_name} ({columns_str}) VALUES ({values_str}) ON CONFLICT DO NOTHING;\"\n",
    "    \n",
    "    # Prepare the data for insertion\n",
    "    data_to_insert = [tuple(row) for row in df.to_numpy()]\n",
    "    \n",
    "    try:\n",
    "        # Use execute_batch for efficient bulk inserts\n",
    "        execute_batch(cursor, insert_query, data_to_insert)\n",
    "        conn.commit()\n",
    "        print(\"Data loaded successfully into the database.\")\n",
    "    except psycopg2.Error as e:\n",
    "        conn.rollback()  # Rollback the transaction in case of error\n",
    "        print(\"An error occurred while inserting data into the database:\")\n",
    "        print(e)\n",
    "    finally:\n",
    "        cursor.close()\n",
    "\n",
    "table_name = \"teams_active\"  \n",
    "load_data_to_db(conn, teams_active_df_transformed, table_name)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
